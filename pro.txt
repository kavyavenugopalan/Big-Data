Architecture:
EC2(python script for temperature sensor iot data) ----> Kinesis stream ---->Kinesis Analysis(anomaly detection)
---->kinesis firehose----->Elastic search domain ----> Kibana Visualization
----------------------------------------------------------------------------------------------------------------------------
intallations:
1) putty
2)boto
3)awscliv2
----------------------------------------------------------------------------------------------------------------------------
Create Kinesis stream
Create Analytics Application
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
python temperature code (temperature.py)
-----------------------

import json
import datetime
import random
import testdata
from boto import kinesis

 
kinesis = kinesis.connect_to_region("us-east-1")

def getData(iotName, lowVal, highVal):
	data = {}
	data["iotName"] = iotName
	data["iotValue"] = random.randint(lowVal, highVal)
	return data

while 1:

	rnd = random.random()
	if (rnd < 0.01):
		data = json.dumps(getData("DemoSensor", 100, 120))
		kinesis.put_record("RawStreamData", data, "DemoSensor")
		print '***************************** anomaly ************************* ' + data
else:
	data = json.dumps(getData("DemoSensor", 10, 20))
	kinesis.put_record("RawStreamData", data, "DemoSensor")
	print data

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL to create stream and insert data to output stream:
------------------------------------------------------

CREATE OR REPLACE STREAM "TEMP_STREAM" (

         "iotName"        varchar (40),

         "iotValue"   integer,

         "ANOMALY_SCORE"  DOUBLE);

      -- Creates an output stream and defines a schema

      CREATE OR REPLACE STREAM "DESTINATION_SQL_STREAM" (

         "iotName"       varchar(40),

         "iotValue"       integer,

         "ANOMALY_SCORE"  DOUBLE,

         "created" TimeStamp);

      

      -- Compute an anomaly score for each record in the source stream

      -- using Random Cut Forest

      CREATE OR REPLACE PUMP "STREAM_PUMP_1" AS INSERT INTO "TEMP_STREAM"

      SELECT STREAM "iotName", "iotValue", ANOMALY_SCORE FROM

        TABLE(RANDOM_CUT_FOREST(

          CURSOR(SELECT STREAM * FROM "SOURCE_SQL_STREAM_001")

        )

      );

 

      -- Sort records by descending anomaly score, insert into output stream

      CREATE OR REPLACE PUMP "OUTPUT_PUMP" AS INSERT INTO "DESTINATION_SQL_STREAM"

      SELECT STREAM "iotName", "iotValue", ANOMALY_SCORE, ROWTIME FROM "TEMP_STREAM"

      ORDER BY FLOOR("TEMP_STREAM".ROWTIME TO SECOND), ANOMALY_SCORE DESC;

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

EC2 linux instance
-------------------

aws configure

curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip

sudo ./aws/install -i /usr/local/aws-cli -b /usr/local/bin


4)sudo yum -y install python-pip
5)sudo pip install boto3
6)sudo pip install testdata
------------------------------------------------------------------------------------
Creating opensearch domain

/usr/local/bin/aws opensearch create-domain --domain-name my-transcribe-test
 --engine-version OpenSearch_1.0 --cluster-config  InstanceType=t2.medium.search,InstanceCount=1
 --ebs-options EBSEnabled=true,VolumeType=standard,VolumeSize=10 --access-policies
 '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"AWS":"arn:aws:iam::992833567489:root"},
"Action":"es:*","Resource":"arn:aws:es:us-west-2:992833567489:domain/my-transcribe-test/*"}]}' --region us-east-1

-----------------------------------------------------------------------------------------------------------------------------
Create firehose that send data to opensearch
---------------------------------------------------------------------------------------------------------------------------
open kibana and go to dashboards. Create index pattern.
-----------------------------------------------------------------------------------------------------------------------


